% !TeX_ROOT=../thesis.tex

\chapter{TFHE}



\section{Basics on $\LWE$ and $\GLWE$ Encryption}


\subsection{Hardness assumptions}


\paragraph{Original $\LWE$ problem}

In 2005, Regev defined the Learning With Errors ($\LWE$) problem in \cite{regev_lwe}. With this work, he laid the foundations for an important part of modern lattice-based cryptography. The version usually used in FHE is presented in Definition \ref{def:LWE}:


\begin{definition}
	(Learning with Errors). Let $q$ and $n$ two integers, respectively called \textit{modulus} and \textit{dimension}.  and let $\chi_s$ and $\chi_e$ be distributions over the small values of $\lweRing$. We sample a vector $\vec s = (s_0, \dots, s_{n-1}) \drawfrom \chi_s^n$. 
	
	We define the $\LWE$ distribution $\mathcal{D}_{q, n, \chi_s, \chi_e}^{\LWE}$ as:
	
	 \[
	 \mathcal{D}_{q, n, \chi_s, \chi_e}^{\LWE} = \left \{(\vec a, b) \;\middle|\; \vec a = (a_0, \dots, a_{n-1}) \drawfrom \unif{\lweRing}^n, e \drawfrom \chi_e, b = \sum_{j=0}^{n-1} a_j \cdot s_j + e \right \}
	  \]
	 
	 The \textit{decisional} version of the problem is to distinguish this distribution from a uniformely random one, namely:
	
	\[
	\mathcal{D}^{(\textsf{random})} = \left \{(\vec a, r) \;\middle|\; \vec a \drawfrom \unif{\lweRing}^n, r \drawfrom \unif{\lweRing} \right\}
	\]

	The \emph{search} version of the problem is to recover $\vec s$ from samples of $\mathcal{D}_{q, n, \chi_s, \chi_e}^{\LWE}$. 
	\label{def:LWE}
\end{definition}


Regev showed that the search and decisional problems are reducible to each other and their average case is as hard as worst-case lattice problems.

The hardness of this problem depends on the parameters $q$, $n$, $\chi_s$ and $\chi_e$, and so does the security of the schemes built upon it. To derive a concrete security level $\lambda$ from a parameter set, state of the art is a tool named \texttt{lattice-estimator} \cite{lattice-estimator}. Users can input concrete values and distributions for the parameters, and the tool evaluates the security of the underlying $\LWE$ instance by running simulations of attacks of the literature.

In Definition \ref{def:LWE}, we did not precise the shapes of the distributions $\chi_s$ and $\chi_e$ (beyond yielding small values). So many distributions are possible: a discrete Gaussian with a small variance, a uniform distribution restricted on a small interval, or a binomial. 

Most of implementations of TFHE select a uniform distribution on $\{0, 1\}$ for the secret, and a Gaussian with a small variance $\lweSigma$. Thus, we will use these one in this thesis. We will use the notation $\LWE_{(q, n, \sigma)}$ for these instances.



\paragraph{Extension to the Polynomials: $\GLWE$}


Looking for more efficient solutions, $\LWE$ problem has been declined in a \textit{ring variant} in \cite{rlwe}, and further expanded in a multitude of variants since them. A generalized version over ring, named $\GLWE$ and used by TFHE, is presented below. It is very similar to the original one, but deals with polynomial values instead of integers:

\begin{definition}
	(Generalized Learning with Errors) Let $q$, $k$ and $N$ three integers, respectively called \textit{modulus}, \textit{dimension} and \textit{degree}. Let $\chi_S$ and $\chi_E$ be distributions over the small values of $\glweRing$. We sample a vector $\vec S = (S_0, \dots, S_{k-1}) \drawfrom \chi_S^k$. 
	
	We define the $\GLWE$ distribution $\mathcal{D}_{q, k, N, \chi_S, \chi_E}^{\GLWE}$ as:
	
	\[
	\mathcal{D}_{q, k, N, \chi_S, \chi_E}^{\GLWE} = \left \{ (\vec A, B) \;\middle|\; \vec A = (A_0, \dots, A_{k-1}) \drawfrom \unif{\glweRing}^k, E \drawfrom \chi_E, B = \sum_{j=0}^{k-1} A_j \cdot S_j + E \right \}
	\]
	
	The \textit{decisional} version of the problem is to distinguish this distribution from a uniformely random one, namely:
	
	\[
	\mathcal{D}^{(\textsf{random})} = \left \{(\vec A, R) \;\middle|\; \vec A \drawfrom \unif{\glweRing}^k, R \drawfrom \unif{\glweRing} \right\}
	\]
	
	The \emph{search} version of the problem is to recover $\vec S$ from samples of $\mathcal{D}_{q, k , N, \chi_S, \chi_E}^{\GLWE}$. 
	\label{def:GLWE}
	
\end{definition}

Note that if we fix $k = 1$, we fall back on the classical $\RLWE$ problem, notably used in BGV \cite{bgv}. Also, taking $N=1$ produces a $\LWE$ instance with $n = k$. 

Concretely, using polynomial rings allows to encode more information in a single sample, yielding more compact ciphertexts and public keys. The schemes can also benefit from high-speed polynomial arithmetic techniques such as FFT. 

General consensus is that hardness of an instance $\GLWE_{(q, k, N, \sigma)}$ is similar to the hardness of $\LWE_{(q, k \cdot N, \sigma)}$, which makes possible to use the \texttt{lattice-estimator} as well.


\TODO{Je ne trouve pas de reference pour ce claim, mais c'est ce que tout le monde fait}






\section{A Word on the Torus equivalence and its discretization}
\ref{sec:torus_equivalence}


The T in TFHE stands for \textit{Torus}. This is because in the seminal paper of TFHE \cite{}, authors have worked with a torus-based version of $\LWE$ in order to 

\TODO{Comprendre rationale et introduire le tore d'un point de vue mathématique}


When implementing the scheme in practice, torus elements are represented by integer types. The torus is thus seen as \textit{discretized}, which we denote by 

\[ \T_q = \left \{   \frac a q \;\middle|\; a \in \Z_q  \right \} \]$ 

with $q = 2^\Omega$ ($\Omega$ denotes the number of bits of precision of the concrete type, so often 32 or 64 bits in most implementations). It is not hard to see that the properties of the torus structure are preserved.

This thesis being mainly about practical instantiations of the scheme, for the sake of clarity we will adopt a notation closer to the reality of the objects manipulated in machine. So the torus elements will be seen as elements of $\lweRing$ (but keeping the rules imposed by the structure of $\T$).



\section{Encryption and Decryption in TFHE}





\section{Linear Homomorphism}




\section{Key Switching and Bootstrapping}







\section{A deep-dive into the Programmable Bootstrapping algorithm}

In his seminal paper, Gentry introduced the concept of bootstrapping, that can be summed up in one phrase by:

\begin{quote}
	Evaluating homomorphically the decryption circuit on a noisy ciphertext produces a new ciphertext encrypting the same value, but with a smaller noise level.
\end{quote}

So informally, for a bootstrapping procedure to work, one needs to provide the server \textit{an encryption of the secret key}. This key is called a \textit{Bootstrapping Key}.



Let $c$ be a ciphertext encrypting a message $m$, with some noise $e$, under a key $s$. We recall that TFHE's decryption circuit looks like:

\begin{enumerate}
	\item Computing the phase of the ciphertext: $\phi(c) = b - \sum_{i=0}^{n-1} a_i \cdot s_i = m + e$.
	\item Rounding the phase to the closest plaintext: $m = \rounding{\phi(c)}$.
\end{enumerate}


Step 1. being purely linear, it is very easy to perform using TFHE's trivial linear homomorphism (at the cost of significant noise growth). But Step 2. is less clear: How to perform rounding homomorphically ? 

In the following, we will explain these two steps, and introduce key concepts such as \textit{Gadget Decompositions}, \textit{External Products} or \textit{Blind Rotation}. A first piece will be dedicated to computing Step 1. with the noise growth the most limited possible. Then, we will see how to implement Step 2. by leveraging some polynomial algebra.

\section{Computing the scalar product without noise explosion}

Let $c = (a_0, \dots, a_{n-1}, b)$ be a \LWE ciphertext encrypting a message $m$ under a key $s = (s_0, \dots, s_{n-1}) \in \B^n$. The client has encrypted this key under a second one $s_2$. For now, we suppose that the \LWE flavour of encryption is used as well (we will see in the following that this is not the case in practice, but it makes the explanation clearer). So, the \textit{bootstrapping key} is a collection of $n$ ciphertexts encrypting each of the bits of $s$.

\begin{equation}
	\BSK = \left ( \texttt{Enc}(s_0), \dots, \texttt{Enc}(s_{n-1}) \right )
\end{equation}



From $c$ and $\BSK$, it is easy to see that Step 1. can be trivially computed homomorphically by:

\begin{equation*}
	\sumTFHETernary{\clearMultTFHE{\texttt{Enc}(s_0)}{a_0}}{\dots}{\clearMultTFHE{\texttt{Enc}(s_{n-1})}{a_{n-1}}}
\end{equation*}


The major problem with this approach lies in the \textit{noise growth}: remember that the $a_i$'s are sampled at random in the ring $\lweRing$. So the expectation of their magnitude will be very high relatively to the size of the ring. But when multiplying with a cleartext, the noise of a ciphertext is multiplied by the same amount. Thus, we need a more sophisticated multiplication algorithm with a better noise behavior.

Enters \textit{Gadget Decomposition}, introduced in \cite{GSW13}. We give an informal view of the algorithm in the following paragraph.


\paragraph{Gadget Decomposition: }


Let $c$ be a \LWE ciphertext and $\alpha$ a constant, sampled uniformely at random in $\lweRing$. Directly multiplying every component of the ciphertext by $\alpha$ would also multiply the noise by the same amount. Gadget Decomposition is a construction allowing to performm this homomorphic multiplication while limiting noise growth.





\section{A look at Blind Rotation}

\TODO{Trouver le papier d'où ça vient, et l'expliquer aved des zolis dessins}



\section{External product}


