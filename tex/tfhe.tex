% !TeX_ROOT=../thesis.tex

\chapter{TFHE}



\section{Basics on $\LWE$ Encryption}


\subsection{Hardness assumption}


In 2005, Regev defined the Learning With Errors ($\LWE$) problem in \cite{regev}. With this work, it laid the foundations for an important part of modern lattice-based cryptography. The version usually used in FHE is presented in Definition \ref{def:LWE}:


\begin{definition}
	(Learning with Errors). Let $q$ and $n$ two integers, respectively called \textit{modulus} and \textit{dimension}.  and let $\chi_s$ and $\chi_e$ be a distribution over the small values of $\lweRing$. We sample a vector $\vec s = (s_0, \dots, s_{n-1}) \drawfrom \chi_s^n$. 
	
	We define the $\LWE$ distribution $\mathcal{D}_{q, n, \chi_s, \chi_e}^{\LWE}$ as:
	
	 \[
	 \mathcal{D}_{q, n, \chi_s, \chi_e}^{\LWE} = \left \{(\vec a, b)~\mid~\vec a = (a_1, \dots, a_n) \drawfrom \unif{\lweRing}^n, e \drawfrom \chi_e, b = \sum_{j=1}^n a_j \cdot s_j + e \right \}
	  \]
	 
	 The \textit{decisional} version of the problem is to distinguish this distribution from a uniformely random one, namely:
	
	\[\mathcal{D}^{(\textsf{random})} = \{(\vec a, r)~\mid~\vec a \drawfrom \unif{\lweRing}^n, r \drawfrom \unif{\lweRing}\}\]

	The \emph{search} version of the problem is to recover $\vec s$ from samples of $\mathcal{D}_{q, n, \chi_s, \chi_e}^{\LWE}$. 
	\label{def:LWE}
\end{definition}



Both the search and decisional problems are reducible to each other \cite{Regev-LWE} and their average case is as hard as worst-case lattice problems.


The  hardness of this problem depends on the parameters $q$, $n$, $\chi_s$ and $\chi_e$. 


The distributions can be gaussian, binomial, uniform, etc...


\TODO{Finir cette prtie et gerer crypto.bib}





\section{Extending to the Polynomials}



\section{A Word on the Torus}
\ref{sec:torus_equivalence}












\section{A deep-dive into the Programmable Bootstrapping algorithm}

In his seminal paper, Gentry introduced the concept of bootstrapping, that can be summed up in one phrase by:

\begin{quote}
	Evaluating homomorphically the decryption circuit on a noisy ciphertext produces a new ciphertext encrypting the same value, but with a smaller noise level.
\end{quote}

So informally, for a bootstrapping procedure to work, one needs to provide the server \textit{an encryption of the secret key}. This key is called a \textit{Bootstrapping Key}.



Let $c$ be a ciphertext encrypting a message $m$, with some noise $e$, under a key $s$. We recall that TFHE's decryption circuit looks like:

\begin{enumerate}
	\item Computing the phase of the ciphertext: $\phi(c) = b - \sum_{i=0}^{n-1} a_i \cdot s_i = m + e$.
	\item Rounding the phase to the closest plaintext: $m = \rounding{\phi(c)}$.
\end{enumerate}


Step 1. being purely linear, it is very easy to perform using TFHE's trivial linear homomorphism (at the cost of significant noise growth). But Step 2. is less clear: How to perform rounding homomorphically ? 

In the following, we will explain these two steps, and introduce key concepts such as \textit{Gadget Decompositions}, \textit{External Products} or \textit{Blind Rotation}. A first piece will be dedicated to computing Step 1. with the noise growth the most limited possible. Then, we will see how to implement Step 2. by leveraging some polynomial algebra.

\section{Computing the scalar product without noise explosion}

Let $c = (a_0, \dots, a_{n-1}, b)$ be a \LWE ciphertext encrypting a message $m$ under a key $s = (s_0, \dots, s_{n-1}) \in \B^n$. The client has encrypted this key under a second one $s_2$. For now, we suppose that the \LWE flavour of encryption is used as well (we will see in the following that this is not the case in practice, but it makes the explanation clearer). So, the \textit{bootstrapping key} is a collection of $n$ ciphertexts encrypting each of the bits of $s$.

\begin{equation}
	\BSK = \left ( \texttt{Enc}(s_0), \dots, \texttt{Enc}(s_{n-1}) \right )
\end{equation}



From $c$ and $\BSK$, it is easy to see that Step 1. can be trivially computed homomorphically by:

\begin{equation*}
	\sumTFHETernary{\clearMultTFHE{\texttt{Enc}(s_0)}{a_0}}{\dots}{\clearMultTFHE{\texttt{Enc}(s_{n-1})}{a_{n-1}}}
\end{equation*}


The major problem with this approach lies in the \textit{noise growth}: remember that the $a_i$'s are sampled at random in the ring $\lweRing$. So the expectation of their magnitude will be very high relatively to the size of the ring. But when multiplying with a cleartext, the noise of a ciphertext is multiplied by the same amount. Thus, we need a more sophisticated multiplication algorithm with a better noise behavior.

Enters \textit{Gadget Decomposition}, introduced in \cite{GSW13}. We give an informal view of the algorithm in the following paragraph.


\paragraph{Gadget Decomposition: }


Let $c$ be a \LWE ciphertext and $\alpha$ a constant, sampled uniformely at random in $\lweRing$. Directly multiplying every component of the ciphertext by $\alpha$ would also multiply the noise by the same amount. Gadget Decomposition is a construction allowing to performm this homomorphic multiplication while limiting noise growth.





\section{A look at Blind Rotation}

\TODO{Trouver le papier d'où ça vient, et l'expliquer aved des zolis dessins}



\section{External product}


