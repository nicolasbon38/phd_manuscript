\section{Experimental Results}
\label{sec:comparison}

In this section, we compare our new framework to several state-of-the-art homomorphic \gls{AES} executions, including the ones performed with the two building blocks of our new design.
We particularly emphasize that \textit{all implementations have been tested on the same machine}, a 12th Gen Intel(R) Core(TM) i7-12700H CPU laptop with 64 Gib total system memory with an Ubuntu 22.04.2 LTS operating system. All execution timings can be found in Table~\ref{tab:comp}.
Parameter sets used to obtain these results are presented in Table~\ref{tab:params}.
Depending on the framework, we had to use different implementations of \gls{TFHE} as available in the \texttt{TFHElib}\footnote{\url{https://tfhe.github.io/tfhe/}}, \texttt{tfhe-rs}\footnote{\url{https://github.com/zama-ai/tfhe-rs}} or \texttt{TFHEpp}\footnote{\url{https://github.com/virtualsecureplatform/TFHEpp}} libraries.


\begin{table}[htbp]
\caption{Parameters sets used for our homomorphic \gls{AES} evaluation, with $\lambda\approx128$ bits as the security parameter. $\perr$ denotes the probability of bootstrapping failure. $\baseDecompKS$ and $\levelDecompKS$ denote the basis and levels associated with the gadget decomposition in \KeySwitch, $\baseDecompPBS$ and $\levelDecompPBS$ denote the decomposition basis and the precision of the decomposition of \BlindRotate. $\lweSigma$ and $\glweSigma$ are the standard deviations of noises used in $\LWE$ and $\GLWE$ ciphertexts, respectively.}
\label{tab:params}
\begin{adjustbox}{center}
\begin{tabular}{|c||c|c|c|c|c|c|c|c|c|}
\hline
 $\perr$ &  $n$   & $N$ & $k$   & $\levelDecompPBS$ & $\baseDecompPBS$ & $\baseDecompKS$ & $\levelDecompKS$ & $\lweSigma$ & $\glweSigma$ \\ \hline
  $2^{-40}$ & 754     &    1024  & 1  &  2   &    $2^{23}$   &   $2^4$     &   3  &  $2^{46.4}$       &    $2^{16.7}$       \\ \hline  
    $2^{-128}$ &   900    &   4096   & 1  &   2  &   $2^{15}$   &    $2^3$    &  6 &    $2^{44.5}$      &    $2^2$      \\ \hline  
\end{tabular}
\end{adjustbox}
\end{table}

%
\begin{table}[ht]
\centering
\caption{Comparison of our method with different state-of-the art approaches \emph{on a single core}. The only execution timing that was not obtained on our machine is marked with a $^*$, i.e. for Thunderbird, making the comparison more in favor of that method. See the discussion at the end of Section \ref{sec:thunderbird}.}
\label{tab:comp}
\begin{tabular}{|>{\centering\arraybackslash}p{0.8cm}|>{\centering\arraybackslash}p{3.2cm}|>{\centering\arraybackslash}p{4cm}|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|}
\hline
\textbf{Year} & \textbf{Reference} & \textbf{Framework} & \textbf{Library} & \textbf{Timings (s)} \\
\hline
\multirow{3}{*}{2023} & \cite{DBLP:conf/wahc/TramaCBS23} & Tree-Based Method (\gls{TBM}) & \texttt{TFHElib} \footnote{https://tfhe.github.io/tfhe/} & 270\\
\cline{2-5}
& \cite{TCHES:BonPoiRiv24}, Chap. \ref{chap:p_encodings} & $p$-encoding method & \texttt{tfhe-rs}\footnote{https://github.com/zama-ai/tfhe-rs} & 90\\
\cline{2-5}
& \cite{ISC:WWLLL23} & Fregata & \texttt{TFHEpp} \footnote{https://github.com/virtualsecureplatform/TFHEpp} & 87\\
\hline
2024 & \cite{TCHES:WLWLLW24} & Thunderbird & \texttt{TFHEpp} \footnote{https://github.com/virtualsecureplatform/TFHEpp} & $46^*$ \\
\hline \hline
2025 & this work & \hippo & \texttt{tfhe-rs}\footnote{https://github.com/zama-ai/tfhe-rs} & 32\\
\hline
\end{tabular}
\end{table}


The implementation of \hippo~and the unified software test bench for \gls{AES} execution over \gls{TFHE}, which we used to obtain the consistent same-machine experimental results presented in this paper, are available as open-source Git repositories\footnote{\url{https://github.com/CryptoExperts/Hippogryph} and \url{https://github.com/daphnetrm/Benchmark-of-\gls{AES}-Evaluation-with-\gls{TFHE}}.}.


\subsection{State-Of-The-Art Homomorphic \gls{AES} Executions}
The approaches introduced in \cite{DBLP:conf/wahc/TramaCBS23} and \cite{TCHES:BonPoiRiv24}, which form the foundation of our proposal, are discussed in \ref{sec:previous-blocks}. Additionally, we briefly describe the two other main state-of-the-art methods for homomorphic \gls{AES} executions: Fregata \cite{ISC:WWLLL23} and Thunderbird \cite{TCHES:WLWLLW24}.


\subsubsection{Fregata \cite{ISC:WWLLL23}}
In this work, the authors present a novel evaluation framework especially designed for faster \gls{AES} homomorphic evaluation. Instead of relying on functional bootstrapping, they decided to use CMUX gate as the building block of their framework. They also propose a new technique for an efficient \gls{S-box} evaluation relying on mixed packing (which combines different ways of organizing encrypted data within polynomials to balance parallelism and flexibility). %\RS{(ici on balance ça comme si le reviewer était supposé savoir mais du coup il manque une micro-parenthèse donnant un pouillème d'intuition)}. 
%\SB{proposition : They also propose a new technique for an efficient \gls{S-box} evaluation relying on mixed packing, which combines different ways of organizing encrypted data within polynomials to balance parallelism and flexibility.}
But one of the major contributions of this work is the optimization of \gls{TFHE}'s circuit bootstrapping. Indeed, they propose to use PBSManyLUT \cite{AC:CLOT21} in the first step of circuit bootstrapping. As their framework relies on the use of \gls{TFHE} in LHE mode, this optimization of circuit bootstrapping is the key to an efficient homomorphic \gls{AES} evaluation. Fregata being designed to perform one round of \gls{AES} without any bootstrapping and to use circuit bootstrapping on each bit of the state matrix after a full round evaluation, running these circuit bootstrappings then becomes the most time consuming part.
Finally, they also leverage on encoding messages in $\{0, 1\}$ as $\{0, \frac{1}{2}\}$ over the torus to transform XOR operations into simple LWE sums (which is the same thing as using our $(2, 2)$-encoding in the linear parts).

Their results, obtained with the TFHEpp library \cite{TFHEpp}, reached an \gls{AES} homomorphic evaluation latency of 86 seconds on a 12th Gen Intel(R) Core(TM) i5-12500× 12 with 15.3 GB RAM machine. When running the Fregata implementation\footnote{https://github.com/WeiBenqiang/Fregata} on our machine, we also obtained a latency of about 87 seconds.


\subsubsection{Thunderbird \cite{TCHES:WLWLLW24}}
\label{sec:thunderbird}
The work presented in the Thunderbird paper leverages on the Fregata framework to produce an even faster \gls{AES} homomorphic evaluation, still using TFHEpp. Specifically, Thunderbird combines the gate bootstrapping and leveled evaluation modes of \gls{TFHE} to cater to various function types within symmetric encryption algorithms. More specifically, their approach builds upon the Fregata framework with additional optimizations:
\begin{itemize}
    \item The circuit bootstrapping proposed in Fregata is optimized by replacing the second step (namely a private keyswitch) by a public keyswitch followed by a new operation called \texttt{EvalSquareMult}.
    \item  Instead of following a standard \gls{AES} implementation, the authors introduce a \gls{LUT}-based \gls{AES} implementation that merges SubBytes, ShiftRows and MixColumns operations into 8-to-32-bit tables (which results in a smaller number of XOR operations when running the overall \gls{AES}).
\end{itemize}
Moreover, as in \cite{ISC:WWLLL23}, they rely on encoding the messages in $\{0, 1\}$ as $\{0, \frac{1}{2}\}$ over the Torus. With such encoding, XOR operation can be performed for free. They call this optimization \texttt{FreeXOR}. They also propose another technique to evaluate XOR, namely \texttt{HomoXOR} relying on gate bootstrapping with messages encoded in $\{\frac{-1}{8}, \frac{1}{8}\}$ over the Torus. The evaluation of \gls{AES} with this technique is less efficient than with \texttt{FreeXOR}. For this work, the tests were run on an Intel(R) Core(TM) i5-11500 CPU @ 2.70GHz machine with 32 GB of RAM and they obtained an average execution latency of 46 seconds.

% Since the Thunderbird code is not publicly available, we have made every effort to fully re-implement it. We successfully reproduced all of its building blocks but one--the improved circuit-bootstrapping--which was producing decryption errors despite our best efforts to faithfully follow the Thunderbird paper. Unfortunately, our attempts to seek clarification from the paper’s authors did not yield helpful responses to help us resolve these issues. 
% As a consequence, for this specific building block, we relied on the theoretical speedup reported in the Thunderbird paper, which results in a slightly unfair comparison to our approach. We will revise the paragraph (lines 540-549 on p. 18) to clarify this point.  


It is important to note that the implementation of the Thunderbird framework is not publicly available. To obtain a fair comparison with our work, we tried to reproduce their results by implementing the framework ourselves, starting from Fregata on which Thunderbird is based. We successfully implemented all of Thunderbird building blocks but one--the improved circuit-bootstrapping--which was producing decryption errors despite our best efforts to faithfully follow \cite{TCHES:WLWLLW24}. As a consequence, for this specific building block, we relied on the theoretical speedup reported in the Thunderbird paper, which results in a slightly unfair comparison to our approach. In summary, \emph{we measured an \gls{AES} execution time of 60 secs with our implementation, but used instead the 46 secs reported in \cite{TCHES:WLWLLW24} for comparison}. 

\begin{comment}
% Renaud> je me suis permis de commenter ceci et je propose de remplacer tout ça par le texte en vert ci-dessus (plus simple et plus clair je pense). Qu'en pensez-vous?
\DT{Despite our best efforts to faithfully follow the Thunderbird paper, our implementation of their framework} (using the most efficient \texttt{FreeXOR} variant) still induced unexpected decryption errors. \DT{Looking for comparison figures, we still executed it and obtained an \gls{AES} execution in 60 secs, which was a bit slower than the 46 seconds reported by the authors.} This hints that our machine is approximately 1.3 times slower than the one used in their paper (a ratio which is further confirmed by lower-grain unitary measurements on the circuit bootstrapping alone). \DT{Finally, as our implementation did not always produce correct results, we choose not to rely on it for comparison.} 
As a consequence, for this specific building block only, we relied on the theoretical speedup reported in the Thunderbird paper, which results in a slightly unfair comparison to our approach. \emph{As a result, comparing the execution times of our new framework to those reported in the Thunderbird paper (i.e. 46 secs) may slightly disadvantage \hippo.}
\NB{On a dit dans le rebuttal qu'on améliorerait cette section} \DT{J'ai fait quelques ajouts en partant de notre réponse de rebuttal, mais je ne sais pas si c'est vraiment plus clair qu'auparavant...}
\end{comment}

%\SB{proposition pour la dernière phrase : \emph{As a result, comparing the execution times of our new framework to those reported for Thunderbird may slightly disadvantage \hippo.} \RS{OK j'ai fait une très légère variante ci-dessus}} 

%Still, we were able to correctly run the \texttt{HomoXOR} variant of Thunderbird without their newly optimized circuit bootstrapping (i.e. with the circuit bootstrapping from Fregata). This implementation takes about $170$ seconds for a full \gls{AES}, with a measured unitary circuit bootstrapping timing of about 60 ms. In the Thunderbird paper, the authors claim to get the circuit bootstrapping timing down to $36$ ms (by using a public keyswitch along with \texttt{EvalSquareMult} instead of a private keyswitch). With such unitary timings for the circuit bootstrapping, a complete implementation of the \texttt{HomoXOR} variant of Thunderbird would run in about $139$ seconds \todo{(as 128 circuit bootstrappings per \gls{AES} rounds are performed)} vs 110 seconds given in the Thunderbird paper. This seems to lead to a consistent ratio of about 1.3 between the speed of their machine compared to ours. \emph{We thus assume that comparing the execution timings of our new framework to those given in the Thunderbird paper results in a slightly unfair comparison for \hippo.}}


%\new{we were not able to obtain a fully functional implementation}, we were able to correctly run a version of Thunderbird without their newly optimized circuit bootstrapping (i.e. with the circuit bootstrapping from Fregata) but including their faster \texttt{HomoXOR} method. This implementation takes about $170$ seconds for a full \gls{AES}, with a measured unitary circuit bootstrapping timing of about 60 ms. In the Thunderbird paper, the authors claim to get the circuit bootstrapping timing down to $36$ ms with their optimized variant (that uses a public keyswitch along with \texttt{EvalSquareMult} instead of a private keyswitch). With such unitary timings for the circuit bootstrapping, a complete implementation of the Thunderbird framework would run in about $139$ seconds \todo{(as 128 circuit bootstrappings per \gls{AES} rounds are performed)} vs 110 seconds given in the Thunderbird paper. Consistently, our complete implementation of the framework executed the \gls{AES} in 60 secs vs 46 secs in the Thunderbird paper leading to a consistent ratio of about 1.3 between the speed of their machine compare to our.
%We thus assume that comparing the execution timings of our new framework to those given in the Thunderbird paper results in a slightly unfair comparison for \hippo.}

\subsection{Results}
To measure the performances of our method, we implemented it using our fork of \texttt{tfhe-rs} \cite{tfhe-rs}, modified to support odd moduli (see Section \ref{sec:library}). The results were then compared against the current state-of-the-art frameworks.

For a fair comparison, all implementations were tested on the same machine, \emph{using a single core}. As shown in Table \ref{tab:comp}, our novel framework achieves the lowest latency when evaluating the \gls{AES} as the evaluation of the algorithm only takes about 30 seconds. Hence, \hippo{} is between 1.44 and 1.87 times faster than the best-in-class Thunderbird approach (depending, as discussed above, whether we respectively consider the 46 secs timing given in the Thunderbird paper or a timing of 60 secs as measured with our implementation).
Moreover, when enabling several cores on our 12th Gen Intel(R) Core(TM) i7-12700H CPU laptop, we can reach an execution time that is smaller than $5$ seconds, using only 6 cores, and further reduce this timing to 1.1 seconds by using 32 cores on a more powerful machine as discussed below.

\paragraph{A Few Words About Parallelisation.}
The purpose of transciphering is to minimize the bandwidth overhead when transferring large amounts of data. Given that servers typically have more computational resources than clients, they can effectively leverage multiple cores to parallelize computations and enhance execution times. In this context, \gls{AES} offers inherent parallelizability, as most operations within each encryption round can be executed concurrently on each byte of the state matrix—except for the ShiftRows step.

It is worth noting that in practical transciphering applications, one could process multiple \gls{AES} blocks in parallel to achieve better amortized performance. However, the parallelization we apply here focuses on accelerating computations within a single \gls{AES} block, rather than processing multiple blocks independently.

To implement this approach, we used Rust's \texttt{rayon} crate. Our tests were conducted tests on two distinct machines to assess performance across different setups:
\begin{itemize}
\item Laptop (12th Gen Intel(R) Core(TM) i7-12700H CPU, 6 cores): We parallelized all round functions except ShiftRows, which mainly involves reordering ciphertexts within the state matrix. This setup already provided a significant speedup compared to single-core execution: 4.6 seconds for a failure probability of $2^{-40}$.
\item Server (AMD Ryzen Threadripper PRO 7995WX, 96 cores): We leveraged 32 cores to process the 16 bytes of the \gls{AES} internal state in parallel, each using one thread for each of the 2 independents \gls{TBM} in the \SubBytes step. This setup brought us remarkably close to breaking the 1-second barrier, with an execution time of just 1.1 seconds.
\end{itemize}
%
%First, we used the same 12th Gen Intel(R) Core(TM) i7-12700H CPU laptop that was previously used for testing with a single core. This time, we ran the code on the laptop using its six available cores. Specifically, we parallelized every round function except for the ShiftRows function, which mainly involves reordering ciphertexts within the state matrix.
%
%Second, we ran the code on a server with an AMD Ryzen Threadripper PRO 7995WX, equipped with 96 cores, allowing for extended parallelization. \textcolor{red}{We leveraged 32 of them to process the 16 bytes of the \gls{AES} internal state in parallel, each using one thread for each of the 2 independents \gls{TBM} in the \SubBytes step}. \emph{This setup brought us remarkably close to breaking the 1-second barrier, with an execution time of just \textcolor{red}{1.1} seconds.}
%
Detailed execution timings illustrating these improvements can be found in Table \ref{tab:bonus}.


 Memory-wise, our implementation manipulates at most 128 \gls{TFHE} ciphertexts which account for the internal state and $128 \times 11$ other ciphertexts for the round keys. Each \gls{TFHE} ciphertext accounts for around 48 kbits (755*64 bits). Hence, the total memory consumption of our implementation is approximately 74 Mbits when encrypting a single block. When encrypting multiple blocks in parallel, the ciphertexts for the round keys are shared across all blocks, reducing the per-block overhead.


%We implemented a version of our implementation that includes such a parallelization using Rust's \texttt{rayon} crate. Our tests were conducted on two distinct machines. The first, a 12th Gen Intel(R) Core(TM) i7-12700H CPU laptop, was used to run all our tests with the six available cores. The second machine is a server equipped with an AMD Ryzen Threadripper PRO 7995WX, equipped with 96 cores (though only 16 cores were utilized due to the granularity of our parallelization approach, which independently iterates over the 16 bytes of the internal state).

%We initially executed that code over the six cores of the laptop. As a standard laptop, it provides valuable insights into the performance of a partially parallelized homomorphic \gls{AES} implementation. This setup serves as a reasonable indication of the potential benefits of larger-scale parallelization. Consequently, we parallelize every round function except for the ShiftRows function, which primarily involves reorganizing ciphertexts within the state matrix. Nevertheless, by leveraging the capabilities of the \texttt{par\_iter} structure of \texttt{rayon} to iterate efficiently over the bytes of the internal state, we were able to fully exploit up to 16 cores for extensive parallelization on the server. \emph{This optimization brought us remarkably close to breaking the 1-second barrier, achieving a measured execution time of 1.6 seconds.}



\paragraph{Key Expansion:} To the best of our knowledge, all previous works on \gls{AES} transciphering do not perform the key expansion phase in the homomorphic domain. To ensure fair comparisons with related works, we made the same assumption. However, we do have a \gls{TFHE} implementation of key expansion that has roughly the same structure as \hippo. Our measurements show that a run of \KeyExpansion is approximately 20 \% faster than the encryption/decryption. 



\paragraph{What About Recent CPA$^\mathbf{D}$ Attacks?}
To obtain a fair comparison, we use parameters equivalent to those used in the state-of-the-art, that typically achieve an error probability of about $2^{-40}$. But to take into account recent attacks in the CPA$^D$ model \cite{EC:LiMic21} on several FHEs (including \gls{TFHE}) \cite{C:CSBB24, CCS:CCPSS24}, we also give execution times of our approach with a example parameters set achieving an error probability of $2^{-128}$ (Table \ref{tab:params}). When running with such parameters, an \gls{AES} evaluation takes about 463 seconds on our machine, still using a single core (see also Table \ref{tab:bonus}). Although more optimal parameters may be found, this timing also illustrates that achieving CPA$^{D}$ security may have a significant cost on \gls{FHE} performances. At this point, we leave that cost mitigation as a future work.

\begin{table}[H]
\centering
\caption{Different evaluation timings of \hippo~for different setups.}
\label{tab:bonus}
\begin{tabular}{|c|c|c|c|}
\hline
Machine       &  \# cores    & $\perr$          & Timings (s) \\ \hline
laptop        &  1           & $2^{-40}$          &  32         \\ \hline
laptop        &  1           & $2^{-128}$         &  463        \\ \hline
laptop        &  6           & $2^{-40}$          &  4.6        \\ \hline
server        &  32         & $2^{-40}$          &  1.1       \\ \hline
\end{tabular}
\end{table}