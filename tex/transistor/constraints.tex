
\section{Constraints for a \gls{TFHE}-friendly Stream Cipher}
\label{sec:constraints}



%\subsection{State-of-the-Art}
%\label{sec:soa}
%
%While transciphering can theoretically be instantiated with any symmetric cipher, traditional ciphers like \gls{AES} were soon found to be suboptimal~\cite{C:GenHalSma12}, which lead to the design of dedicated ciphers.
%Early proposals in this direction include the {\tt LowMC} family of block ciphers~\cite{EC:ARSTZ15}, which minimizes multiplicative depth, and the {\tt Kreyvium} stream cipher~\cite{FSE:CCFLNP16}, a tweak of the well-known eSTREAM finalist {\tt Trivium}. While {\tt Trivium} itself was not originally designed for homomorphic encryption, both {\tt Trivium} and {\tt Kreyvium} showed competitive performance in \gls{TFHE}-based transciphering scenarios~\cite{DBLP:conf/wahc/BalenboisOS23}.
%
%In 2016, the {\tt FLIP} stream cipher~\cite{EC:MJSC16} introduced the concept of a filter permutator that randomly permutes key bits and applies a non-linear function on the result to generate a keystream bit. The direct application of non-linear filtering on low-noise key bits helps control the noise generated during homomorphic operations. Two variants were then proposed: {\tt FiLIP}~\cite{INDOCRYPT:MCJS19} and {\tt Elisabeth}~\cite{AC:CHMS22}, which aimed for stronger security and improved performance. Most notably, {\tt Elisabeth} operates over arbitrary groups like $\mathbb{Z}_{2^4}$ to minimize costly field conversions in homomorphic evaluations, and it leverages negacyclic lookup tables to eliminate padding bits, thereby optimizing \gls{TFHE} performance. However, in 2023, an algebraic attack successfully compromised {\tt Elisabeth}~\cite{AC:GBJR23}, prompting the design of patched versions: {\tt Elisabeth-b}, {\tt Gabriel}, and {\tt Margrethe}~\cite{INDOCRYPT:HofMeaSta23}. While these variants address the identified vulnerabilities, they introduce trade-offs in efficiency: either the evaluation cost or the communication overhead significantly increases compared to the original {\tt Elisabeth}.
%
%Another recent contribution is the construction of a PRF~\cite{EPRINT:DJLCB24} based on the Learning With Rounding (LWR) problem~\cite{EC:BanPeiRos12}. Computing one PRF output requires only a single \gls{PBS} in the \gls{TFHE} context. Still, the main overhead stems from the transmission of the secret key in GGSW format,\footnote{This technique is a generalization of the one introduced in~\cite{C:GenSahWat13}.}  which is significantly larger than traditional LWE ciphertexts.
%
%Finally, the {\tt FRAST} stream cipher~\cite{FRAST} is built on top of a block cipher with a \gls{TFHE}-friendly round function, %that leverages a random \gls{S-box} to enable a reduced number of rounds,
%and evaluates it efficiently using the double-blind rotation technique combined with WoP-\gls{PBS}. This allows multiple \gls{S-box} invocations to be processed at the cost of a single \gls{PBS}. {\tt FRAST} achieves substantial improvements in throughput while maintaining competitive noise growth. Its main trade-offs lie in a slight increase in communication cost and the need for an initial setup phase to convert GLWE ciphertexts into GGSW form~\cite{C:GenSahWat13}.
%
%Concrete performance figures for all the above-mentioned ciphers are provided in Section~\ref{sec:perfs_soa}.
%
 



%\subsection{Constraints from \gls{TFHE}}
%\label{constraints_tfhe}


\paragraph{\gls{TFHE} Operations.} \gls{TFHE} enables the evaluation of both linear functions and look-up tables on encrypted data, each offering complementary properties.

Linear operations in \gls{TFHE} are highly efficient but contribute to an increase in ciphertext noise. Specifically, when performing a linear combination of ciphertexts $c_1, \ldots, c_n$ with constant coefficients $\alpha_1, \ldots, \alpha_n$, the noise variance increases in proportion to the squared $\ell_2$-norm of the coefficient vector, i.e., $\sum_{i=1}^n \alpha_i^2$.  Therefore, to optimize efficiency and control the noise growth, a \gls{TFHE}-friendly cipher can make greedy use of linear operations while minimizing the norm of the coefficient vectors to limit the resulting noise.

Conversely to linear operations, the programmable Bootstrapping (\gls{PBS}) is a slow operation, but it allows the computation of any (small-precision) function chosen by the designer while reducing the noise in the ciphertext to a nominal level at the same time. Therefore, while we should minimize the number of these operations for the sake of efficiency, they are essential for introducing non-linearity into the cipher and limiting the noise growth throughout the execution. In practice, within our context, the use of \gls{PBS} introduces further constraints which we address below.

\paragraph{The arrangement of operations.} The \gls{PBS} produces ciphertexts with a nominal noise level, which is typically lower than that of the input ciphertexts but still significantly higher than the noise in a fresh ciphertext. This implies that if the input bits are fresh encrypted data, they can undergo complex linear operations (specifically with potentially high $\ell_2$-norms). In contrast, the linear functions applied to the outputs of each \gls{PBS} should involve somewhat limited linear operations in their resulting  $\ell_2$-norms in order to limit the noise growth.

\paragraph{The size of the plaintext space.} The choice of the plaintext space $\mathbb{Z}_p$ has a significant impact on the \gls{PBS}. Indeed, execution time of the \gls{PBS} grows exponentially with the number of bits of $p$, which is therefore usually limited to a few bits. Although some recent works (\cite{TCHES:GuiBorAra21,AC:CLOT21,EPRINT:CZBSG22,TCHES:KluSch23}) introduce more sophisticated techniques for efficiently evaluating larger LUTs, their performance in terms of bits per second remains less favorable compared to using lower precision.


\paragraph{The parity of the plaintext space.} Following the general line of work of this thesis, we chose an odd plaintext modulus $p$ to get rid of the negacyclicity problem. But using an odd modulus may seem unsuitable for manipulating bits or groups of bits. Indeed, it may lead to data expansion, as an element of \( \mathbb{Z}_p \) cannot perfectly encode a group of bits. To mitigate this issue, one can select an odd $p$ that is slightly larger but close to $2^\ell$ for some $\ell$, allowing for the efficient embedding of $\ell$-bit chunks into elements of $\mathbb{Z}_p$. 


\subsubsection{Our design choices.} 

We deduce the following guidelines for our design:
\begin{enumerate}
\item The plaintext space of the scheme will be reduced to a few bits to take advantage of the relative speed of the \gls{PBS} at small precision. Specifically, we chose $p=17$ which meets our constraints as being odd (no negacyclicity) and the closest to a low power of $2$ (thus well suited to encode nibbles of data). Besides, letting $p$ be a prime number eases the design and security analysis thanks to the field structure of $\mathbb{Z}_p = \mathbb{F}_p$.
  
Moreover, operating in $\F_{17}$ does not constrain the server-side application to this field. Once the server retrieves the homomorphic ciphertexts, they can be efficiently converted to any other space with a bootstrapping. We elaborate more on this point in Section~\ref{sec:data_representation}. 


  \item The non-linearity comes from a layer of \gls{S-box}es, each computing a function $\mainField \to \mainField$  giving rise to one \gls{PBS} evaluation. Given our fixed choice of $p$, the number of \gls{PBS} per element of the output stream represents the main performance metric which we search to minimize. 

  
  \item The initial key material (stored as fresh \gls{TFHE} ciphertexts) can go through complex linear combinations
  before hitting the \gls{S-box} layer.
  
  \item Each \gls{S-box} output should only go through lightweight linear operations (i.e., with low $\ell_2$-norms) before undergoing another \gls{PBS} in order to make the noise in the input of the \gls{PBS} sufficiently low to ensure correctness.

  
  \item Each \gls{S-box} output should only go through lightweight linear operations (i.e., with low $\ell_2$-norms) before being
  released. This way, the \gls{TFHE} ciphertexts obtained after the stream-cipher decryption keep a noise level as close to nominal as possible.
\end{enumerate}